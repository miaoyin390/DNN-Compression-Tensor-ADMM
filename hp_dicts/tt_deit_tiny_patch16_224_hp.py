# -*- coding:utf-8 -*-
# 
# Author: MIAO YIN
# Time: 2021/10/11 21:00


class HyperParamsDictRatio2x:
    depth = 12
    num_heads = 3
    embed_dim = 192
    tt_shapes = {
        'blocks.0.attn.qkv.weight':   (24, 24, 12, 16),
        'blocks.0.attn.proj.weight':  (16, 12, 12, 16),
        'blocks.0.mlp.fc1.weight':    (32, 24, 12, 16),
        'blocks.0.mlp.fc2.weight':    (16, 12, 24, 32),
        'blocks.1.attn.qkv.weight':   (24, 24, 12, 16),
        'blocks.1.attn.proj.weight':  (16, 12, 12, 16),
        'blocks.1.mlp.fc1.weight':    (32, 24, 12, 16),
        'blocks.1.mlp.fc2.weight':    (16, 12, 24, 32),
        'blocks.2.attn.qkv.weight':   (24, 24, 12, 16),
        'blocks.2.attn.proj.weight':  (16, 12, 12, 16),
        'blocks.2.mlp.fc1.weight':    (32, 24, 12, 16),
        'blocks.2.mlp.fc2.weight':    (16, 12, 24, 32),
        'blocks.3.attn.qkv.weight':   (24, 24, 12, 16),
        'blocks.3.attn.proj.weight':  (16, 12, 12, 16),
        'blocks.3.mlp.fc1.weight':    (32, 24, 12, 16),
        'blocks.3.mlp.fc2.weight':    (16, 12, 24, 32),
        'blocks.4.attn.qkv.weight':   (24, 24, 12, 16),
        'blocks.4.attn.proj.weight':  (16, 12, 12, 16),
        'blocks.4.mlp.fc1.weight':    (32, 24, 12, 16),
        'blocks.4.mlp.fc2.weight':    (16, 12, 24, 32),
        'blocks.5.attn.qkv.weight':   (24, 24, 12, 16),
        'blocks.5.attn.proj.weight':  (16, 12, 12, 16),
        'blocks.5.mlp.fc1.weight':    (32, 24, 12, 16),
        'blocks.5.mlp.fc2.weight':    (16, 12, 24, 32),
        'blocks.6.attn.qkv.weight':   (24, 24, 12, 16),
        'blocks.6.attn.proj.weight':  (16, 12, 12, 16),
        'blocks.6.mlp.fc1.weight':    (32, 24, 12, 16),
        'blocks.6.mlp.fc2.weight':    (16, 12, 24, 32),
        'blocks.7.attn.qkv.weight':   (24, 24, 12, 16),
        'blocks.7.attn.proj.weight':  (16, 12, 12, 16),
        'blocks.7.mlp.fc1.weight':    (32, 24, 12, 16),
        'blocks.7.mlp.fc2.weight':    (16, 12, 24, 32),
        'blocks.8.attn.qkv.weight':   (24, 24, 12, 16),
        'blocks.8.attn.proj.weight':  (16, 12, 12, 16),
        'blocks.8.mlp.fc1.weight':    (32, 24, 12, 16),
        'blocks.8.mlp.fc2.weight':    (16, 12, 24, 32),
        'blocks.9.attn.qkv.weight':   (24, 24, 12, 16),
        'blocks.9.attn.proj.weight':  (16, 12, 12, 16),
        'blocks.9.mlp.fc1.weight':    (32, 24, 12, 16),
        'blocks.9.mlp.fc2.weight':    (16, 12, 24, 32),
        'blocks.10.attn.qkv.weight':  (24, 24, 12, 16),
        'blocks.10.attn.proj.weight': (16, 12, 12, 16),
        'blocks.10.mlp.fc1.weight':   (32, 24, 12, 16),
        'blocks.10.mlp.fc2.weight':   (16, 12, 24, 32),
        'blocks.11.attn.qkv.weight':  (24, 24, 12, 16),
        'blocks.11.attn.proj.weight': (16, 12, 12, 16),
        'blocks.11.mlp.fc1.weight':   (32, 24, 12, 16),
        'blocks.11.mlp.fc2.weight':   (16, 12, 24, 32),
    }

    ranks = {
        # state_dict key: (output channel, input channel)
        'blocks.0.attn.qkv.weight':   (1, 22, 96, 15, 1),
        'blocks.0.attn.proj.weight':  (1, 15, 96, 15, 1),
        'blocks.0.mlp.fc1.weight':    (1, 30, 96, 15, 1),
        'blocks.0.mlp.fc2.weight':    (1, 15, 96, 30, 1),
        'blocks.1.attn.qkv.weight':   (1, 20, 96, 12, 1),
        'blocks.1.attn.proj.weight':  (1, 12, 96, 12, 1),
        'blocks.1.mlp.fc1.weight':    (1, 28, 96, 12, 1),
        'blocks.1.mlp.fc2.weight':    (1, 12, 96, 28, 1),
        'blocks.2.attn.qkv.weight':   (1, 16, 96, 12, 1),
        'blocks.2.attn.proj.weight':  (1, 12, 96, 12, 1),
        'blocks.2.mlp.fc1.weight':    (1, 22, 96, 12, 1),
        'blocks.2.mlp.fc2.weight':    (1, 12, 96, 22, 1),
        'blocks.3.attn.qkv.weight':   (1, 16, 96, 12, 1),
        'blocks.3.attn.proj.weight':  (1, 12, 96, 12, 1),
        'blocks.3.mlp.fc1.weight':    (1, 22, 96, 12, 1),
        'blocks.3.mlp.fc2.weight':    (1, 12, 96, 22, 1),
        'blocks.4.attn.qkv.weight':   (1, 16, 96, 12, 1),
        'blocks.4.attn.proj.weight':  (1, 12, 96, 12, 1),
        'blocks.4.mlp.fc1.weight':    (1, 22, 96, 12, 1),
        'blocks.4.mlp.fc2.weight':    (1, 12, 96, 22, 1),
        'blocks.5.attn.qkv.weight':   (1, 16, 96, 12, 1),
        'blocks.5.attn.proj.weight':  (1, 12, 96, 12, 1),
        'blocks.5.mlp.fc1.weight':    (1, 22, 96, 12, 1),
        'blocks.5.mlp.fc2.weight':    (1, 12, 96, 22, 1),
        'blocks.6.attn.qkv.weight':   (1, 16, 96, 12, 1),
        'blocks.6.attn.proj.weight':  (1, 12, 96, 12, 1),
        'blocks.6.mlp.fc1.weight':    (1, 22, 96, 12, 1),
        'blocks.6.mlp.fc2.weight':    (1, 12, 96, 22, 1),
        'blocks.7.attn.qkv.weight':   (1, 16, 96, 12, 1),
        'blocks.7.attn.proj.weight':  (1, 12, 96, 12, 1),
        'blocks.7.mlp.fc1.weight':    (1, 22, 96, 12, 1),
        'blocks.7.mlp.fc2.weight':    (1, 12, 96, 22, 1),
        'blocks.8.attn.qkv.weight':   (1, 16, 96, 12, 1),
        'blocks.8.attn.proj.weight':  (1, 12, 96, 12, 1),
        'blocks.8.mlp.fc1.weight':    (1, 22, 96, 12, 1),
        'blocks.8.mlp.fc2.weight':    (1, 12, 96, 22, 1),
        'blocks.9.attn.qkv.weight':   (1, 16, 96, 12, 1),
        'blocks.9.attn.proj.weight':  (1, 12, 96, 12, 1),
        'blocks.9.mlp.fc1.weight':    (1, 22, 96, 12, 1),
        'blocks.9.mlp.fc2.weight':    (1, 12, 96, 22, 1),
        'blocks.10.attn.qkv.weight':  (1, 16, 96, 12, 1),
        'blocks.10.attn.proj.weight': (1, 12, 96, 12, 1),
        'blocks.10.mlp.fc1.weight':   (1, 22, 96, 12, 1),
        'blocks.10.mlp.fc2.weight':   (1, 12, 96, 22, 1),
        'blocks.11.attn.qkv.weight':  (1, 16, 96, 12, 1),
        'blocks.11.attn.proj.weight': (1, 12, 96, 12, 1),
        'blocks.11.mlp.fc1.weight':   (1, 22, 96, 12, 1),
        'blocks.11.mlp.fc2.weight':   (1, 12, 96, 22, 1),
    }